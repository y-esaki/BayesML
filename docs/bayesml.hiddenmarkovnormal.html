
<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>bayesml.hiddenmarkovnormal package &#8212; BayesML</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=362ab14a" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>

    <script src="_static/documentation_options.js?v=46e1a7d4"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'bayesml.hiddenmarkovnormal';</script>
    <link rel="icon" href="_static/BayesML_favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="bayesml.linearregression package" href="bayesml.linearregression.html" />
    <link rel="prev" title="bayesml.gaussianmixture package" href="bayesml.gaussianmixture.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/BayesML_logo.png" class="logo__image only-light" alt="BayesML - Home"/>
    <script>document.write(`<img src="_static/BayesML_logo.png" class="logo__image only-dark" alt="BayesML - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="bayesml.html">bayesml package</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="bayesml.autoregressive.html">bayesml.autoregressive package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.bernoulli.html">bayesml.bernoulli package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.categorical.html">bayesml.categorical package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.contexttree.html">bayesml.contexttree package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.exponential.html">bayesml.exponential package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.gaussianmixture.html">bayesml.gaussianmixture package</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">bayesml.hiddenmarkovnormal package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.linearregression.html">bayesml.linearregression package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.metatree.html">bayesml.metatree package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.multivariate_normal.html">bayesml.multivariate_normal package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.normal.html">bayesml.normal package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.poisson.html">bayesml.poisson package</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="developers.html">BayesML Developers</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/yuta-nakahara/BayesML" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/bayesml.hiddenmarkovnormal.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>bayesml.hiddenmarkovnormal package</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-bayesml.hiddenmarkovnormal">Module contents</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel"><code class="docutils literal notranslate"><span class="pre">GenModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.get_constants"><code class="docutils literal notranslate"><span class="pre">GenModel.get_constants()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.set_params"><code class="docutils literal notranslate"><span class="pre">GenModel.set_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.set_h_params"><code class="docutils literal notranslate"><span class="pre">GenModel.set_h_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.get_params"><code class="docutils literal notranslate"><span class="pre">GenModel.get_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.get_h_params"><code class="docutils literal notranslate"><span class="pre">GenModel.get_h_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.gen_params"><code class="docutils literal notranslate"><span class="pre">GenModel.gen_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.gen_sample"><code class="docutils literal notranslate"><span class="pre">GenModel.gen_sample()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.save_sample"><code class="docutils literal notranslate"><span class="pre">GenModel.save_sample()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.visualize_model"><code class="docutils literal notranslate"><span class="pre">GenModel.visualize_model()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel"><code class="docutils literal notranslate"><span class="pre">LearnModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.get_constants"><code class="docutils literal notranslate"><span class="pre">LearnModel.get_constants()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.set_h0_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.set_h0_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.get_h0_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.get_h0_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.set_hn_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.set_hn_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.get_hn_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.get_hn_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.update_posterior"><code class="docutils literal notranslate"><span class="pre">LearnModel.update_posterior()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.estimate_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.estimate_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.visualize_posterior"><code class="docutils literal notranslate"><span class="pre">LearnModel.visualize_posterior()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.get_p_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.get_p_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.calc_pred_dist"><code class="docutils literal notranslate"><span class="pre">LearnModel.calc_pred_dist()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.make_prediction"><code class="docutils literal notranslate"><span class="pre">LearnModel.make_prediction()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.pred_and_update"><code class="docutils literal notranslate"><span class="pre">LearnModel.pred_and_update()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.estimate_latent_vars"><code class="docutils literal notranslate"><span class="pre">LearnModel.estimate_latent_vars()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.estimate_latent_vars_and_update"><code class="docutils literal notranslate"><span class="pre">LearnModel.estimate_latent_vars_and_update()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="bayesml-hiddenmarkovnormal-package">
<h1>bayesml.hiddenmarkovnormal package<a class="headerlink" href="#bayesml-hiddenmarkovnormal-package" title="Link to this heading">#</a></h1>
<img alt="_images/hiddenmarkovnormal_example.png" src="_images/hiddenmarkovnormal_example.png" />
<section id="module-bayesml.hiddenmarkovnormal">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-bayesml.hiddenmarkovnormal" title="Link to this heading">#</a></h2>
<p>The hidden Markov model with the Gauss-Wishart prior distribution and the Dirichlet prior distribution.</p>
<p>The stochastic data generative model is as follows:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(K \in \mathbb{N}\)</span>: number of latent classes</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{z} \in \{ 0, 1 \}^K\)</span>: a one-hot vector representing the latent class (latent variable)</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\pi} \in [0, 1]^K\)</span>: a parameter for latent classes, (<span class="math notranslate nohighlight">\(\sum_{k=1}^K \pi_k=1\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(a_{j,k} \in [0,1]\)</span> : transition probability to latent state k under latent state j</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{a}_j = [a_{j,1}, a_{j,2}, \dots , a_{j,K}]\in [0,1]^K\)</span>, a vector of the transition probability (<span class="math notranslate nohighlight">\(\sum_{k=1}^K a_{j,k}=1\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{A}=(a_{j,k})_{1\leq j,k\leq K} \in [0, 1]^{K\times K}\)</span>: a matrix of the transition probability</p></li>
<li><p><span class="math notranslate nohighlight">\(D \in \mathbb{N}\)</span>: a dimension of data</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{x} \in \mathbb{R}^D\)</span>: a data point</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\mu}_k \in \mathbb{R}^D\)</span>: a parameter</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\mu} = \{ \boldsymbol{\mu}_k \}_{k=1}^K\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\Lambda}_k \in \mathbb{R}^{D\times D}\)</span> : a parameter (a positive definite matrix)</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\Lambda} = \{ \boldsymbol{\Lambda}_k \}_{k=1}^K\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(| \boldsymbol{\Lambda}_k | \in \mathbb{R}\)</span>: the determinant of <span class="math notranslate nohighlight">\(\boldsymbol{\Lambda}_k\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}p(\boldsymbol{z}_{1} | \boldsymbol{\pi}) &amp;= \mathrm{Cat}(\boldsymbol{z}_{1}|\boldsymbol{\pi}) = \prod_{k=1}^K \pi_k^{z_{1,k}},\\
p(\boldsymbol{z}_{n} |\boldsymbol{z}_{n-1} ,\boldsymbol{A}) &amp;= \prod_{k=1}^K \prod_{j=1}^K a_{j,k}^{z_{n-1,j}z_{n,k}},\\
p(\boldsymbol{x}_{n} | \boldsymbol{\mu}, \boldsymbol{\Lambda}, \boldsymbol{z}_{n}) &amp;= \prod_{k=1}^K \mathcal{N}(\boldsymbol{x}|\boldsymbol{\mu}_k,\boldsymbol{\Lambda}_k^{-1})^{z_{n,k}} \\
&amp;= \prod_{k=1}^K \left( \frac{| \boldsymbol{\Lambda}_{k} |^{1/2}}{(2\pi)^{D/2}} \exp \left\{ -\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu}_{k})^\top \boldsymbol{\Lambda}_{k} (\boldsymbol{x}-\boldsymbol{\mu}_{k}) \right\} \right)^{z_{n,k}},\end{split}\]</div>
<p>The prior distribution is as follows:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{m}_0 \in \mathbb{R}^{D}\)</span>: a hyperparameter</p></li>
<li><p><span class="math notranslate nohighlight">\(\kappa_0 \in \mathbb{R}_{&gt;0}\)</span>: a hyperparameter</p></li>
<li><p><span class="math notranslate nohighlight">\(\nu_0 \in \mathbb{R}\)</span>: a hyperparameter (<span class="math notranslate nohighlight">\(\nu_0 &gt; D-1\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{W}_0 \in \mathbb{R}^{D\times D}\)</span>: a hyperparameter (a positive definite matrix)</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\eta}_0 \in \mathbb{R}_{&gt; 0}^K\)</span>: a hyperparameter</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\zeta}_{0,j} \in \mathbb{R}_{&gt; 0}^K\)</span>: a hyperparameter</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathrm{Tr} \{ \cdot \}\)</span>: a trace of a matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Gamma (\cdot)\)</span>: the gamma function</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}p(\boldsymbol{\mu},\boldsymbol{\Lambda},\boldsymbol{\pi},\boldsymbol{A}) &amp;= \left\{ \prod_{k=1}^K \mathcal{N}(\boldsymbol{\mu}_k|\boldsymbol{m}_0,(\kappa_0 \boldsymbol{\Lambda}_k)^{-1})\mathcal{W}(\boldsymbol{\Lambda}_k|\boldsymbol{W}_0, \nu_0) \right\} \mathrm{Dir}(\boldsymbol{\pi}|\boldsymbol{\eta}_0) \prod_{j=1}^{K}\mathrm{Dir}(\boldsymbol{a}_{j}|\boldsymbol{\zeta}_{0,j}), \\
&amp;= \Biggl[ \prod_{k=1}^K \left( \frac{\kappa_0}{2\pi} \right)^{D/2} |\boldsymbol{\Lambda}_k|^{1/2} \exp \left\{ -\frac{\kappa_0}{2}(\boldsymbol{\mu}_k -\boldsymbol{m}_0)^\top \boldsymbol{\Lambda}_k (\boldsymbol{\mu}_k - \boldsymbol{m}_0) \right\} \\
&amp;\qquad \times B(\boldsymbol{W}_0, \nu_0) | \boldsymbol{\Lambda}_k |^{(\nu_0 - D - 1) / 2} \exp \left\{ -\frac{1}{2} \mathrm{Tr} \{ \boldsymbol{W}_0^{-1} \boldsymbol{\Lambda}_k \} \right\}\biggl] \\
&amp;\qquad \times \Biggl[ \prod_{k=1}^KC(\boldsymbol{\eta}_0)\pi_k^{\eta_{0,k}-1}\biggl]\\
&amp;\qquad \times \biggl[\prod_{j=1}^KC(\boldsymbol{\zeta}_{0,j})\prod_{k=1}^K a_{j,k}^{\zeta_{0,j,k}-1}\Biggr],\\\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(B(\boldsymbol{W}_0, \nu_0)\)</span> and <span class="math notranslate nohighlight">\(C(\boldsymbol{\eta}_0)\)</span> are defined as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}B(\boldsymbol{W}_0, \nu_0) &amp;= | \boldsymbol{W}_0 |^{-\nu_0 / 2} \left( 2^{\nu_0 D / 2} \pi^{D(D-1)/4} \prod_{i=1}^D \Gamma \left( \frac{\nu_0 + 1 - i}{2} \right) \right)^{-1}, \\
C(\boldsymbol{\eta}_0) &amp;= \frac{\Gamma(\sum_{k=1}^K \eta_{0,k})}{\Gamma(\eta_{0,1})\cdots\Gamma(\eta_{0,K})},\\
C(\boldsymbol{\zeta}_{0,j}) &amp;= \frac{\Gamma(\sum_{k=1}^K \zeta_{0,j,k})}{\Gamma(\zeta_{0,j,1})\cdots\Gamma(\zeta_{0,j,K})}. \end{split}\]</div>
<p>The apporoximate posterior distribution in the <span class="math notranslate nohighlight">\(t\)</span>-th iteration of a variational Bayesian method is as follows:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{x}^n = (\boldsymbol{x}_1, \boldsymbol{x}_2, \dots , \boldsymbol{x}_n) \in \mathbb{R}^{D \times n}\)</span>: given data</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{z}^n = (\boldsymbol{z}_1, \boldsymbol{z}_2, \dots , \boldsymbol{z}_n) \in \{ 0, 1 \}^{K \times n}\)</span>: latent classes of given data</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{m}_{n,k}^{(t)} \in \mathbb{R}^{D}\)</span>: a hyperparameter</p></li>
<li><p><span class="math notranslate nohighlight">\(\kappa_{n,k}^{(t)} \in \mathbb{R}_{&gt;0}\)</span>: a hyperparameter</p></li>
<li><p><span class="math notranslate nohighlight">\(\nu_{n,k}^{(t)} \in \mathbb{R}\)</span>: a hyperparameter <span class="math notranslate nohighlight">\((\nu_n &gt; D-1)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{W}_{n,k}^{(t)} \in \mathbb{R}^{D\times D}\)</span>: a hyperparameter (a positive definite matrix)</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\eta}_n^{(t)} \in \mathbb{R}_{&gt; 0}^K\)</span>: a hyperparameter</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\zeta}_{n,j}^{(t)} \in \mathbb{R}_{&gt; 0}^K\)</span>: a hyperparameter</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}&amp;q(\boldsymbol{z}^n, \boldsymbol{\mu},\boldsymbol{\Lambda},\boldsymbol{\pi},\boldsymbol{A}) \nonumber \\
&amp;= q^{(t)}(\boldsymbol{z}^n) \left\{ \prod_{k=1}^K \mathcal{N}(\boldsymbol{\mu}_k|\boldsymbol{m}_{n,k}^{(t)},(\kappa_{n,k}^{(t)} \boldsymbol{\Lambda}_k)^{-1})\mathcal{W}(\boldsymbol{\Lambda}_k|\boldsymbol{W}_{n,k}^{(t)}, \nu_{n,k}^{(t)}) \right\} \mathrm{Dir}(\boldsymbol{\pi}|\boldsymbol{\eta}_n^{(t)})\left\{\prod_{j=1}^K\mathrm{Dir}(\boldsymbol{a}_j|\boldsymbol{\zeta}_{n,j}^{(t)})\right\}, \\
&amp;= q^{(t)}(\boldsymbol{z}^n) \Biggl[ \prod_{k=1}^K \left( \frac{\kappa_{n,k}^{(t)}}{2\pi} \right)^{D/2} |\boldsymbol{\Lambda}_k|^{1/2} \exp \left\{ -\frac{\kappa_{n,k}^{(t)}}{2}(\boldsymbol{\mu}_k -\boldsymbol{m}_{n,k}^{(t)})^\top \boldsymbol{\Lambda}_k (\boldsymbol{\mu}_k - \boldsymbol{m}_{n,k}^{(t)}) \right\} \\
&amp;\qquad \times B(\boldsymbol{W}_{n,k}^{(t)}, \nu_{n,k}^{(t)}) | \boldsymbol{\Lambda}_k |^{(\nu_{n,k}^{(t)} - D - 1) / 2} \exp \left\{ -\frac{1}{2} \mathrm{Tr} \{ ( \boldsymbol{W}_{n,k}^{(t)} )^{-1} \boldsymbol{\Lambda}_k \} \right\} \Biggr] \\
&amp;\qquad \times C(\boldsymbol{\eta}_n^{(t)})\prod_{k=1}^K \pi_k^{\eta_{n,k}^{(t)}-1}\left[\prod_{j=1}^K C(\boldsymbol{\zeta}_{n,j}^{(t)})\prod_{k=1}^K a_{j,k}^{\zeta_{n,j,k}^{(t)}-1}\right],\\\end{split}\]</div>
<p>where the updating rule of the hyperparameters is as follows.</p>
<div class="math notranslate nohighlight">
\[\begin{split}N_k^{(t)} &amp;= \sum_{i=1}^n \gamma^{(t)}_{i,k}, \\
M_{j,k}^{(t)} &amp;= \sum_{i=2}^n \xi^{(t)}_{i,j,k},\\
\bar{\boldsymbol{x}}_k^{(t)} &amp;= \frac{1}{N_k^{(t)}} \sum_{i=1}^n \gamma^{(t)}_{i,k} \boldsymbol{x}_i, \\
S_k^{(t)} &amp;= \frac{1}{N_k^{(t)}}\sum_{i=1}^n \gamma^{(t)}_{i,k} (x_i-\bar{\boldsymbol{x}}_k^{(t)})(x_i-\bar{\boldsymbol{x}}_k^{(t)})^{\top},\\
\boldsymbol{m}_{n,k}^{(t+1)} &amp;= \frac{\kappa_0\boldsymbol{\mu}_0 + N_k^{(t)} \bar{\boldsymbol{x}}_k^{(t)}}{\kappa_0 + N_k^{(t)}}, \\
\kappa_{n,k}^{(t+1)} &amp;= \kappa_0 + N_k^{(t)}, \\
(\boldsymbol{W}_{n,k}^{(t+1)})^{-1} &amp;= \boldsymbol{W}_0^{-1} + N_k^{(t)}S_k^{(t)} + \frac{\kappa_0 N_k^{(t)}}{\kappa_0 + N_k^{(t)}}(\bar{\boldsymbol{x}}_k^{(t)}-\boldsymbol{\mu}_0)(\bar{\boldsymbol{x}}_k^{(t)}-\boldsymbol{\mu}_0)^\top, \\
\nu_{n,k}^{(t+1)} &amp;= \nu_0 + N_k^{(t)},\\
\eta_{n,k}^{(t+1)} &amp;= \eta_{0,k} + \gamma^{(t)}_{1,k}, \\
\zeta_{n,j,k}^{(t+1)} &amp;= \zeta_{0,j,k}+M_{j,k}^{(t)}.\end{split}\]</div>
<p>The approximate posterior distribution of the latent variable <span class="math notranslate nohighlight">\(q^{(t+1)}(z^n)\)</span> is calculated by the forward-backward algorithm as follows.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\ln \rho_{i,k}^{(t+1)} &amp;= \frac{1}{2} \Biggl[\, \sum_{d=1}^D \psi \left( \frac{\nu_{n,k}^{(t+1)} + 1 - d}{2} \right) + D \ln 2 + \ln | \boldsymbol{W}_{n,k}^{(t+1)} | \notag \\
&amp;\qquad - D \ln (2 \pi ) - \frac{D}{\kappa_{n,k}^{(t+1)}} - \nu_{n,k}^{(t+1)} (\boldsymbol{x}_i - \boldsymbol{m}_{n,k}^{(t+1)})^\top \boldsymbol{W}_{n,k}^{(t+1)} (\boldsymbol{x}_i - \boldsymbol{m}_{n,k}^{(t+1)}) \Biggr], \\
\ln \tilde{\pi}_k^{(t+1)} &amp;= \psi (\eta_{n,k}^{(t+1)}) - \psi \left( \textstyle \sum_{k=1}^K \eta_{n,k}^{(t+1)} \right) \\
\ln \tilde{a}_{j,k}^{(t+1)} &amp;= \psi (\zeta_{n,j,k}^{(t+1)}) - \psi \left( \textstyle \sum_{k=1}^K \zeta_{n,j,k}^{(t+1)} \right) \\
\alpha^{(t+1)} (\boldsymbol{z}_i) &amp;\propto
\begin{cases}
\prod_{k=1}^{K} \left( \rho_{i,k}^{(t+1)}\right)^{z_{i,k}} \sum_{\boldsymbol{z}_{i-1}} \left[\prod_{k=1}^{K}\prod_{j=1}^{K}\left(\tilde{a}^{(t+1)}_{j,k}\right)^{z_{i-1,j}z_{i,k}}\alpha^{(t+1)}(\boldsymbol{z}_{i-1})\right] &amp; (i&gt;1)\\
\prod_{k=1}^{K}\left( \rho_{1,k}^{(t+1)} \tilde{\pi}_k^{(t+1)} \right)^{z_{1,k}} &amp; (i=1)
\end{cases} \\
\beta^{(t+1)} (\boldsymbol{z}_i) &amp;\propto
\begin{cases}
\sum_{\boldsymbol{z}_{i+1}} \left[ \prod_{k=1}^{K} \left( \rho_{i+1,k}^{(t+1)}\right)^{z_{i+1,k}} \prod_{k=1}^{K}\prod_{j=1}^{K}\left(\tilde{a}^{(t+1)}_{j,k}\right)^{z_{i,j}z_{i+1,k}}\beta^{(t+1)}(\boldsymbol{z}_{i+1})\right] &amp; (i&lt;n)\\
1 &amp; (i=n)
\end{cases} \\
q^{(t+1)}(\boldsymbol{z}_i) &amp;\propto \alpha^{(t+1)}(\boldsymbol{z}_i)\beta^{(t+1)}(\boldsymbol{z}_i) \\
\gamma^{(t+1)}_{i,k} &amp;= \sum_{\boldsymbol{z}_i} q^{(t+1)}(\boldsymbol{z}_i) z_{i,k}\\
q^{(t+1)}(\boldsymbol{z}_{i-1}, \boldsymbol{z}_{i}) &amp;\propto \alpha^{(t+1)}(\boldsymbol{z}_{i-1}) \prod_{k=1}^{K} \left( \rho_{i,k}^{(t+1)}\right)^{z_{i,k}} \prod_{k=1}^{K}\prod_{j=1}^{K}\left(\tilde{a}^{(t+1)}_{j,k}\right)^{z_{i-1,j}z_{i,k}} \beta^{(t+1)}(\boldsymbol{z}_i) \\
\xi^{(t+1)}_{i,j,k} &amp;= \sum_{\boldsymbol{z}_{i-1}} \sum_{\boldsymbol{z}_i} q^{(t+1)}(\boldsymbol{z}_{i-1}, \boldsymbol{z}_{i}) z_{i-1,j} z_{i,k}\end{split}\]</div>
<p>The approximate predictive distribution is as follows:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{x}_{n+1} \in \mathbb{R}^D\)</span>: a new data point</p></li>
<li><p><span class="math notranslate nohighlight">\((a_{\mathrm{p},j,k})_{1\leq j,k\leq K} \in [0, 1]^{K\times K}\)</span>: the parameters of the predictive transition probability of latent classes, (<span class="math notranslate nohighlight">\(\sum_{k=1}^K a_{\mathrm{p},j,k}=1\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\mu}_{\mathrm{p},k} \in \mathbb{R}^D\)</span>: the parameter of the predictive distribution</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\Lambda}_{\mathrm{p},k} \in \mathbb{R}^{D \times D}\)</span>: the parameter of the predictive distribution (a positive definite matrix)</p></li>
<li><p><span class="math notranslate nohighlight">\(\nu_{\mathrm{p},k} \in \mathbb{R}_{&gt;0}\)</span>: the parameter of the predictive distribution</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}&amp;p(x_{n+1}|x^n) \\
&amp;\approx \sum_{k=1}^K \left( \sum_{j=1}^K \gamma_{n,j}^{(t)} a_{\mathrm{p},j,k} \right) \mathrm{St}(x_{n+1}|\boldsymbol{\mu}_{\mathrm{p},k},\boldsymbol{\Lambda}_{\mathrm{p},k}, \nu_{\mathrm{p},k}) \\
&amp;= \sum_{k=1}^K \left( \sum_{j=1}^K \gamma_{n,j}^{(t)} a_{\mathrm{p},j,k} \right)\Biggl[ \frac{\Gamma (\nu_{\mathrm{p},k} / 2 + D / 2)}{\Gamma (\nu_{\mathrm{p},k} / 2)} \frac{|\boldsymbol{\Lambda}_{\mathrm{p},k}|^{1/2}}{(\nu_{\mathrm{p},k} \pi)^{D/2}} \nonumber \\
&amp;\qquad \qquad \qquad \qquad \qquad \times \left( 1 + \frac{1}{\nu_{\mathrm{p},k}} (\boldsymbol{x}_{n+1} - \boldsymbol{\mu}_{\mathrm{p},k})^\top \boldsymbol{\Lambda}_{\mathrm{p},k} (\boldsymbol{x}_{n+1} - \boldsymbol{\mu}_{\mathrm{p},k}) \right)^{-\nu_{\mathrm{p},k}/2 - D/2} \Biggr],\end{split}\]</div>
<p>where the parameters are obtained from the hyperparameters of the predictive distribution as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}a_{\mathrm{p},j,k} &amp;= \frac{\zeta_{n,j,k}^{(t)}}{\sum_{k=1}^K \zeta_{n,j,k}^{(t)}}, \\
\boldsymbol{\mu}_{\mathrm{p},k} &amp;= \boldsymbol{m}_{n,k}^{(t)}, \\
\boldsymbol{\Lambda}_{\mathrm{p},k} &amp;= \frac{\kappa_{n,k}^{(t)} (\nu_{n,k}^{(t)} - D + 1)}{\kappa_{n,k}^{(t)} + 1} \boldsymbol{W}_{n,k}^{(t)}, \\
\nu_{\mathrm{p},k} &amp;= \nu_{n,k}^{(t)} - D + 1.\end{split}\]</div>
<dl class="py class">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.GenModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bayesml.hiddenmarkovnormal.</span></span><span class="sig-name descname"><span class="pre">GenModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">c_num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_degree</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pi_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a_mat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mu_vecs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda_mats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_eta_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_zeta_vecs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_m_vecs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_kappas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_nus</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_w_mats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.GenModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="bayesml.html#bayesml.base.Generative" title="bayesml.base.Generative"><code class="xref py py-class docutils literal notranslate"><span class="pre">Generative</span></code></a></p>
<p>The stochastic data generative model and the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>c_num_classes</strong><span class="classifier">int</span></dt><dd><p>a positive integer</p>
</dd>
<dt><strong>c_degree</strong><span class="classifier">int</span></dt><dd><p>a positive integer</p>
</dd>
<dt><strong>pi_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of real numbers in <span class="math notranslate nohighlight">\([0, 1]\)</span>, 
by default [1/c_num_classes, 1/c_num_classes, … , 1/c_num_classes].
Sum of its elements must be 1.0.</p>
</dd>
<dt><strong>a_mat</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A matrix of real numbers in <span class="math notranslate nohighlight">\([0, 1]\)</span>, 
by default a matrix obtained by stacking 
[1/c_num_classes, 1/c_num_classes, … , 1/c_num_classes].
Sum of the elements of each row vector must be 1.0.
If a single vector is input, will be broadcasted.</p>
</dd>
<dt><strong>mu_vecs</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Vectors of real numbers, 
by default zero vectors.
If a single vector is input, will be broadcasted.</p>
</dd>
<dt><strong>lambda_mats</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Positive definite symetric matrices, 
by default the identity matrices.
If a single matrix is input, it will be broadcasted.</p>
</dd>
<dt><strong>h_eta_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of positive real numbers, 
by default [1/2, 1/2, … , 1/2]</p>
</dd>
<dt><strong>h_zeta_vecs</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Vectors of positive numbers, 
by default vectors whose elements are all 1/2
If a single vector is input, will be broadcasted.</p>
</dd>
<dt><strong>h_m_vecs</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Vectors of real numbers, 
by default zero vectors
If a single vector is input, will be broadcasted.</p>
</dd>
<dt><strong>h_kappas</strong><span class="classifier">float or numpy.ndarray, optional</span></dt><dd><p>Positive real numbers, 
by default [1.0, 1.0, … , 1.0].
If a single real number is input, it will be broadcasted.</p>
</dd>
<dt><strong>h_nus</strong><span class="classifier">float or numpy.ndarray, optional</span></dt><dd><p>Real numbers greater than <code class="docutils literal notranslate"><span class="pre">c_degree-1</span></code>,  
by default [c_degree, c_degree, … , c_degree]
If a single real number is input, it will be broadcasted.</p>
</dd>
<dt><strong>h_w_mats</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Positive definite symetric matrices, 
by default the identity matrices.
If a single matrix is input, it will be broadcasted.</p>
</dd>
<dt><strong>seed</strong><span class="classifier">{None, int}, optional</span></dt><dd><p>A seed to initialize numpy.random.default_rng(), 
by default None</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable table autosummary">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.GenModel.gen_params" title="bayesml.hiddenmarkovnormal.GenModel.gen_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gen_params</span></code></a>()</p></td>
<td><p>Generate the parameter from the prior distribution.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.GenModel.gen_sample" title="bayesml.hiddenmarkovnormal.GenModel.gen_sample"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gen_sample</span></code></a>(sample_length)</p></td>
<td><p>Generate a sample from the stochastic data generative model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.GenModel.get_constants" title="bayesml.hiddenmarkovnormal.GenModel.get_constants"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_constants</span></code></a>()</p></td>
<td><p>Get constants of GenModel.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.GenModel.get_h_params" title="bayesml.hiddenmarkovnormal.GenModel.get_h_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_h_params</span></code></a>()</p></td>
<td><p>Get the hyperparameters of the prior distribution.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.GenModel.get_params" title="bayesml.hiddenmarkovnormal.GenModel.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>()</p></td>
<td><p>Get the parameter of the sthocastic data generative model.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_h_params</span></code>(filename)</p></td>
<td><p>Load the hyperparameters to h_params.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_params</span></code>(filename)</p></td>
<td><p>Load the parameters saved by <code class="docutils literal notranslate"><span class="pre">save_params</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_h_params</span></code>(filename)</p></td>
<td><p>Save the hyperparameters using python <code class="docutils literal notranslate"><span class="pre">pickle</span></code> module.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_params</span></code>(filename)</p></td>
<td><p>Save the parameters using python <code class="docutils literal notranslate"><span class="pre">pickle</span></code> module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.GenModel.save_sample" title="bayesml.hiddenmarkovnormal.GenModel.save_sample"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_sample</span></code></a>(filename, sample_length)</p></td>
<td><p>Save the generated sample as NumPy <code class="docutils literal notranslate"><span class="pre">.npz</span></code> format.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.GenModel.set_h_params" title="bayesml.hiddenmarkovnormal.GenModel.set_h_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_h_params</span></code></a>([h_eta_vec, h_zeta_vecs, ...])</p></td>
<td><p>Set the hyperparameters of the prior distribution.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.GenModel.set_params" title="bayesml.hiddenmarkovnormal.GenModel.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>([pi_vec, a_mat, mu_vecs, lambda_mats])</p></td>
<td><p>Set the parameter of the sthocastic data generative model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.GenModel.visualize_model" title="bayesml.hiddenmarkovnormal.GenModel.visualize_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">visualize_model</span></code></a>([sample_length])</p></td>
<td><p>Visualize the stochastic data generative model and generated samples.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.GenModel.get_constants">
<span class="sig-name descname"><span class="pre">get_constants</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.GenModel.get_constants" title="Link to this definition">#</a></dt>
<dd><p>Get constants of GenModel.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>constants</strong><span class="classifier">dict of {str: int, numpy.ndarray}</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;c_num_classes&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.c_num_classes</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;c_degree&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.c_degree</span></code></p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.GenModel.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pi_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a_mat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mu_vecs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda_mats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.GenModel.set_params" title="Link to this definition">#</a></dt>
<dd><p>Set the parameter of the sthocastic data generative model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>pi_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of real numbers in <span class="math notranslate nohighlight">\([0, 1]\)</span>, 
by default [1/c_num_classes, 1/c_num_classes, … , 1/c_num_classes].
Sum of its elements must be 1.0.</p>
</dd>
<dt><strong>a_mat</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A matrix of real numbers in <span class="math notranslate nohighlight">\([0, 1]\)</span>, 
by default a matrix obtained by stacking 
[1/c_num_classes, 1/c_num_classes, … , 1/c_num_classes].
Sum of the elements of each row vector must be 1.0.
If a single vector is input, will be broadcasted.</p>
</dd>
<dt><strong>mu_vecs</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Vectors of real numbers, 
by default zero vectors.
If a single vector is input, will be broadcasted.</p>
</dd>
<dt><strong>lambda_mats</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Positive definite symetric matrices, 
by default the identity matrices.
If a single matrix is input, it will be broadcasted.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.GenModel.set_h_params">
<span class="sig-name descname"><span class="pre">set_h_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h_eta_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_zeta_vecs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_m_vecs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_kappas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_nus</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_w_mats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.GenModel.set_h_params" title="Link to this definition">#</a></dt>
<dd><p>Set the hyperparameters of the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>h_eta_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of positive real numbers, 
by default [1/2, 1/2, … , 1/2]</p>
</dd>
<dt><strong>h_zeta_vecs</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Vectors of positive numbers, 
by default vectors whose elements are all 1/2
If a single vector is input, will be broadcasted.</p>
</dd>
<dt><strong>h_m_vecs</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Vectors of real numbers, 
by default zero vectors
If a single vector is input, will be broadcasted.</p>
</dd>
<dt><strong>h_kappas</strong><span class="classifier">float or numpy.ndarray, optional</span></dt><dd><p>Positive real numbers, 
by default [1.0, 1.0, … , 1.0].
If a single real number is input, it will be broadcasted.</p>
</dd>
<dt><strong>h_nus</strong><span class="classifier">float or numpy.ndarray, optional</span></dt><dd><p>Real numbers greater than <code class="docutils literal notranslate"><span class="pre">c_degree-1</span></code>,  
by default [c_degree, c_degree, … , c_degree]
If a single real number is input, it will be broadcasted.</p>
</dd>
<dt><strong>h_w_mats</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Positive definite symetric matrices, 
by default the identity matrices.
If a single matrix is input, it will be broadcasted.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.GenModel.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.GenModel.get_params" title="Link to this definition">#</a></dt>
<dd><p>Get the parameter of the sthocastic data generative model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>params</strong><span class="classifier">{str:float, numpy.ndarray}</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;pi_vec&quot;</span></code> : The value of <code class="docutils literal notranslate"><span class="pre">self.pi_vec</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;a_mat&quot;</span></code> : The value of <code class="docutils literal notranslate"><span class="pre">self.a_mat</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;mu_vecs&quot;</span></code> : The value of <code class="docutils literal notranslate"><span class="pre">self.mu_vecs</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;lambda_mats&quot;</span></code> : The value of <code class="docutils literal notranslate"><span class="pre">self.lambda_mats</span></code></p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.GenModel.get_h_params">
<span class="sig-name descname"><span class="pre">get_h_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.GenModel.get_h_params" title="Link to this definition">#</a></dt>
<dd><p>Get the hyperparameters of the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>h_params</strong><span class="classifier">{str:float, np.ndarray}</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h_eta_vec&quot;</span></code> : The value of <code class="docutils literal notranslate"><span class="pre">self.h_eta_vec</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h_zeta_vecs&quot;</span></code> : The value of <code class="docutils literal notranslate"><span class="pre">self.h_zeta_vecs</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h_m_vecs&quot;</span></code> : The value of <code class="docutils literal notranslate"><span class="pre">self.h_m_vecs</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h_kappas&quot;</span></code> : The value of <code class="docutils literal notranslate"><span class="pre">self.h_kappas</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h_nus&quot;</span></code> : The value of <code class="docutils literal notranslate"><span class="pre">self.h_nus</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h_w_mats&quot;</span></code> : The value of <code class="docutils literal notranslate"><span class="pre">self.h_w_mats</span></code></p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.GenModel.gen_params">
<span class="sig-name descname"><span class="pre">gen_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.GenModel.gen_params" title="Link to this definition">#</a></dt>
<dd><p>Generate the parameter from the prior distribution.</p>
<p>To confirm the generated vaules, use <cite>self.get_params()</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.GenModel.gen_sample">
<span class="sig-name descname"><span class="pre">gen_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_length</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.GenModel.gen_sample" title="Link to this definition">#</a></dt>
<dd><p>Generate a sample from the stochastic data generative model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>sample_length</strong><span class="classifier">int</span></dt><dd><p>A positive integer</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>x</strong><span class="classifier">numpy ndarray</span></dt><dd><p>2-dimensional array whose shape is 
<code class="docutils literal notranslate"><span class="pre">(sample_length,c_degree)</span></code> .
Its elements are real numbers.</p>
</dd>
<dt><strong>z</strong><span class="classifier">numpy ndarray</span></dt><dd><p>2-dimensional array whose shape is 
<code class="docutils literal notranslate"><span class="pre">(sample_length,c_num_classes)</span></code> 
whose rows are one-hot vectors.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.GenModel.save_sample">
<span class="sig-name descname"><span class="pre">save_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_length</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.GenModel.save_sample" title="Link to this definition">#</a></dt>
<dd><p>Save the generated sample as NumPy <code class="docutils literal notranslate"><span class="pre">.npz</span></code> format.</p>
<p>It is saved as a NpzFile with keyword: “x”, “z”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>filename</strong><span class="classifier">str</span></dt><dd><p>The filename to which the sample is saved.
<code class="docutils literal notranslate"><span class="pre">.npz</span></code> will be appended if it isn’t there.</p>
</dd>
<dt><strong>sample_length</strong><span class="classifier">int</span></dt><dd><p>A positive integer</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.savez_compressed.html#numpy.savez_compressed" title="(in NumPy v1.26)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.savez_compressed</span></code></a></dt><dd></dd>
</dl>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.GenModel.visualize_model">
<span class="sig-name descname"><span class="pre">visualize_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.GenModel.visualize_model" title="Link to this definition">#</a></dt>
<dd><p>Visualize the stochastic data generative model and generated samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>sample_length</strong><span class="classifier">int, optional</span></dt><dd><p>A positive integer, by default 100</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">bayesml</span> <span class="kn">import</span> <span class="n">hiddenmarkovnormal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">hiddenmarkovnormal</span><span class="o">.</span><span class="n">GenModel</span><span class="p">(</span>
<span class="go">        c_num_classes=2,</span>
<span class="go">        c_degree=1,</span>
<span class="go">        mu_vecs=np.array([[5],[-5]]),</span>
<span class="go">        a_mat=np.array([[0.95,0.05],[0.1,0.9]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">visualize_model</span><span class="p">()</span>
<span class="go">pi_vec:</span>
<span class="go">[0.5 0.5]</span>
<span class="go">a_mat:</span>
<span class="go">[[0.95 0.05]</span>
<span class="go">[0.1  0.9 ]]</span>
<span class="go">mu_vecs:</span>
<span class="go">[[ 5.]</span>
<span class="go">[-5.]]</span>
<span class="go">lambda_mats:</span>
<span class="go">[[[1.]]</span>
<span class="go">[[1.]]]</span>
</pre></div>
</div>
<img alt="_images/hiddenmarkovnormal_example.png" src="_images/hiddenmarkovnormal_example.png" />
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.LearnModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bayesml.hiddenmarkovnormal.</span></span><span class="sig-name descname"><span class="pre">LearnModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">c_num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_degree</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_eta_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_zeta_vecs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_m_vecs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_kappas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_nus</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_w_mats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.LearnModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="bayesml.html#bayesml.base.Posterior" title="bayesml.base.Posterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">Posterior</span></code></a>, <a class="reference internal" href="bayesml.html#bayesml.base.PredictiveMixin" title="bayesml.base.PredictiveMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">PredictiveMixin</span></code></a></p>
<p>The posterior distribution and the predictive distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>c_num_classes</strong><span class="classifier">int</span></dt><dd><p>A positive integer.</p>
</dd>
<dt><strong>c_degree</strong><span class="classifier">int</span></dt><dd><p>A positive integer.</p>
</dd>
<dt><strong>h0_eta_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of positive real numbers, 
by default [1/2, 1/2, … , 1/2].
If a real number is input, it will be broadcasted.</p>
</dd>
<dt><strong>h0_zeta_vecs</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Vectors of positive numbers, 
by default vectors whose elements are all 1.0
If a real number or a single vector is input, will be broadcasted.</p>
</dd>
<dt><strong>h0_m_vecs</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Vectors of real numbers, 
by default zero vectors
If a single vector is input, will be broadcasted.</p>
</dd>
<dt><strong>h0_kappas</strong><span class="classifier">float or numpy.ndarray, optional</span></dt><dd><p>Positive real numbers, 
by default [1.0, 1.0, … , 1.0]
If a single real number is input, it will be broadcasted.</p>
</dd>
<dt><strong>h0_nus</strong><span class="classifier">float or numpy.ndarray, optional</span></dt><dd><p>Real numbers greater than c_degree-1, 
by default c_degree.
If a single real number is input, it will be broadcasted.</p>
</dd>
<dt><strong>h0_w_mats</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Positive definite symetric matrices, 
by default the identity matrices
If a single matrix is input, it will be broadcasted.</p>
</dd>
<dt><strong>seed</strong><span class="classifier">{None, int}, optional</span></dt><dd><p>A seed to initialize numpy.random.default_rng(),
by default None.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>h0_w_mats_inv</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>the inverse matrices of h0_w_mats</p>
</dd>
<dt><strong>hn_eta_vec</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>A vector of positive real numbers</p>
</dd>
<dt><strong>hn_zeta_vecs</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>Vectors of positive numbers</p>
</dd>
<dt><strong>hn_m_vecs</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>Vectors of real numbers.</p>
</dd>
<dt><strong>hn_kappas</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>Positive real numbers</p>
</dd>
<dt><strong>hn_nus</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>Real numbers greater than c_degree-1.</p>
</dd>
<dt><strong>hn_w_mats</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>Positive definite symetric matrices.</p>
</dd>
<dt><strong>hn_w_mats_inv</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>the inverse matrices of hn_w_mats</p>
</dd>
<dt><strong>p_mu_vecs</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>vectors of real numbers</p>
</dd>
<dt><strong>p_nus</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>positive real numbers</p>
</dd>
<dt><strong>p_lambda_mats</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>positive definite symetric matrices</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable table autosummary">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.LearnModel.calc_pred_dist" title="bayesml.hiddenmarkovnormal.LearnModel.calc_pred_dist"><code class="xref py py-obj docutils literal notranslate"><span class="pre">calc_pred_dist</span></code></a>()</p></td>
<td><p>Calculate the parameters of the predictive distribution.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.LearnModel.estimate_latent_vars" title="bayesml.hiddenmarkovnormal.LearnModel.estimate_latent_vars"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_latent_vars</span></code></a>(x[, loss, viterbi])</p></td>
<td><p>Estimate latent variables under the given criterion.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.LearnModel.estimate_latent_vars_and_update" title="bayesml.hiddenmarkovnormal.LearnModel.estimate_latent_vars_and_update"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_latent_vars_and_update</span></code></a>(x[, loss, ...])</p></td>
<td><p>Estimate latent variables and update the posterior sequentially.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.LearnModel.estimate_params" title="bayesml.hiddenmarkovnormal.LearnModel.estimate_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_params</span></code></a>([loss])</p></td>
<td><p>Estimate the parameter under the given criterion.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.LearnModel.get_constants" title="bayesml.hiddenmarkovnormal.LearnModel.get_constants"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_constants</span></code></a>()</p></td>
<td><p>Get constants of LearnModel.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.LearnModel.get_h0_params" title="bayesml.hiddenmarkovnormal.LearnModel.get_h0_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_h0_params</span></code></a>()</p></td>
<td><p>Get the hyperparameters of the prior distribution.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.LearnModel.get_hn_params" title="bayesml.hiddenmarkovnormal.LearnModel.get_hn_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_hn_params</span></code></a>()</p></td>
<td><p>Get the hyperparameters of the posterior distribution.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.LearnModel.get_p_params" title="bayesml.hiddenmarkovnormal.LearnModel.get_p_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_p_params</span></code></a>()</p></td>
<td><p>Get the parameters of the predictive distribution.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_h0_params</span></code>(filename)</p></td>
<td><p>Load the hyperparameters to h0_params.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_hn_params</span></code>(filename)</p></td>
<td><p>Load the hyperparameters to hn_params.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.LearnModel.make_prediction" title="bayesml.hiddenmarkovnormal.LearnModel.make_prediction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_prediction</span></code></a>([loss])</p></td>
<td><p>Predict a new data point under the given criterion.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">overwrite_h0_params</span></code>()</p></td>
<td><p>Overwrite the initial values of the hyperparameters of the posterior distribution by the learned values.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.LearnModel.pred_and_update" title="bayesml.hiddenmarkovnormal.LearnModel.pred_and_update"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pred_and_update</span></code></a>(x[, loss, max_itr, ...])</p></td>
<td><p>Predict a new data point and update the posterior sequentially.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_hn_params</span></code>()</p></td>
<td><p>Reset the hyperparameters of the posterior distribution to their initial values.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_h0_params</span></code>(filename)</p></td>
<td><p>Save the hyperparameters using python <code class="docutils literal notranslate"><span class="pre">pickle</span></code> module.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_hn_params</span></code>(filename)</p></td>
<td><p>Save the hyperparameters using python <code class="docutils literal notranslate"><span class="pre">pickle</span></code> module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.LearnModel.set_h0_params" title="bayesml.hiddenmarkovnormal.LearnModel.set_h0_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_h0_params</span></code></a>([h0_eta_vec, h0_zeta_vecs, ...])</p></td>
<td><p>Set the hyperparameters of the prior distribution.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.LearnModel.set_hn_params" title="bayesml.hiddenmarkovnormal.LearnModel.set_hn_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_hn_params</span></code></a>([hn_eta_vec, hn_zeta_vecs, ...])</p></td>
<td><p>Set the hyperparameter of the posterior distribution.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.LearnModel.update_posterior" title="bayesml.hiddenmarkovnormal.LearnModel.update_posterior"><code class="xref py py-obj docutils literal notranslate"><span class="pre">update_posterior</span></code></a>(x[, max_itr, num_init, ...])</p></td>
<td><p>Update the the posterior distribution using traning data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.hiddenmarkovnormal.LearnModel.visualize_posterior" title="bayesml.hiddenmarkovnormal.LearnModel.visualize_posterior"><code class="xref py py-obj docutils literal notranslate"><span class="pre">visualize_posterior</span></code></a>()</p></td>
<td><p>Visualize the posterior distribution for the parameter.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.LearnModel.get_constants">
<span class="sig-name descname"><span class="pre">get_constants</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.LearnModel.get_constants" title="Link to this definition">#</a></dt>
<dd><p>Get constants of LearnModel.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>constants</strong><span class="classifier">dict of {str: int, numpy.ndarray}</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;c_num_classes&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.c_num_classes</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;c_degree&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.c_degree</span></code></p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.LearnModel.set_h0_params">
<span class="sig-name descname"><span class="pre">set_h0_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h0_eta_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_zeta_vecs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_m_vecs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_kappas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_nus</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_w_mats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.LearnModel.set_h0_params" title="Link to this definition">#</a></dt>
<dd><p>Set the hyperparameters of the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>h0_eta_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of positive real numbers, 
by default [1/2, 1/2, … , 1/2].
If a real number is input, it will be broadcasted.</p>
</dd>
<dt><strong>h0_zeta_vecs</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Vectors of positive numbers, 
by default vectors whose elements are all 1.0
If a real number or a single vector is input, will be broadcasted.</p>
</dd>
<dt><strong>h0_m_vecs</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Vectors of real numbers, 
by default zero vectors
If a single vector is input, will be broadcasted.</p>
</dd>
<dt><strong>h0_kappas</strong><span class="classifier">float or numpy.ndarray, optional</span></dt><dd><p>Positive real numbers, 
by default [1.0, 1.0, … , 1.0]
If a single real number is input, it will be broadcasted.</p>
</dd>
<dt><strong>h0_nus</strong><span class="classifier">float or numpy.ndarray, optional</span></dt><dd><p>Real numbers greater than c_degree-1, 
by default c_degree.
If a single real number is input, it will be broadcasted.</p>
</dd>
<dt><strong>h0_w_mats</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Positive definite symetric matrices, 
by default the identity matrices
If a single matrix is input, it will be broadcasted.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.LearnModel.get_h0_params">
<span class="sig-name descname"><span class="pre">get_h0_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.LearnModel.get_h0_params" title="Link to this definition">#</a></dt>
<dd><p>Get the hyperparameters of the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>h0_params</strong><span class="classifier">dict of {str: numpy.ndarray}</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h0_eta_vec&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.h0_eta_vec</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h0_zeta_vecs&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.h0_zeta_vecs</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h0_m_vecs&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.h0_m_vecs</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h0_kappas&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.h0_kappas</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h0_nus&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.h0_nus</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h0_w_mats&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.h0_w_mats</span></code></p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.LearnModel.set_hn_params">
<span class="sig-name descname"><span class="pre">set_hn_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hn_eta_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hn_zeta_vecs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hn_m_vecs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hn_kappas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hn_nus</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hn_w_mats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.LearnModel.set_hn_params" title="Link to this definition">#</a></dt>
<dd><p>Set the hyperparameter of the posterior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>hn_eta_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of positive real numbers, 
by default [1/2, 1/2, … , 1/2].
If a real number is input, it will be broadcasted.</p>
</dd>
<dt><strong>hn_zeta_vecs</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Vectors of positive numbers, 
by default vectors whose elements are all 1.0
If a real number or a single vector is input, will be broadcasted.</p>
</dd>
<dt><strong>hn_m_vecs</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Vectors of real numbers, 
by default zero vectors
If a single vector is input, will be broadcasted.</p>
</dd>
<dt><strong>hn_kappas</strong><span class="classifier">float or numpy.ndarray, optional</span></dt><dd><p>Positive real numbers, 
by default [1.0, 1.0, … , 1.0]
If a single real number is input, it will be broadcasted.</p>
</dd>
<dt><strong>hn_nus</strong><span class="classifier">float or numpy.ndarray, optional</span></dt><dd><p>Real numbers greater than c_degree-1, 
by default c_degree.
If a single real number is input, it will be broadcasted.</p>
</dd>
<dt><strong>hn_w_mats</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>Positive definite symetric matrices, 
by default the identity matrices
If a single matrix is input, it will be broadcasted.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.LearnModel.get_hn_params">
<span class="sig-name descname"><span class="pre">get_hn_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.LearnModel.get_hn_params" title="Link to this definition">#</a></dt>
<dd><p>Get the hyperparameters of the posterior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>hn_params</strong><span class="classifier">dict of {str: numpy.ndarray}</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;hn_eta_vec&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.hn_eta_vec</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;hn_zeta_vecs&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.hn_zeta_vecs</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;hn_m_vecs&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.hn_m_vecs</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;hn_kappas&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.hn_kappas</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;hn_nus&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.hn_nus</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;hn_w_mats&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.hn_w_mats</span></code></p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.LearnModel.update_posterior">
<span class="sig-name descname"><span class="pre">update_posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_itr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'subsampling'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.LearnModel.update_posterior" title="Link to this definition">#</a></dt>
<dd><p>Update the the posterior distribution using traning data.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>x</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>(sample_length,c_degree)-dimensional ndarray.
All the elements must be real number.</p>
</dd>
<dt><strong>max_itr</strong><span class="classifier">int, optional</span></dt><dd><p>maximum number of iterations, by default 100</p>
</dd>
<dt><strong>num_init</strong><span class="classifier">int, optional</span></dt><dd><p>number of initializations, by default 10</p>
</dd>
<dt><strong>tolerance</strong><span class="classifier">float, optional</span></dt><dd><p>convergence criterion of variational lower bound, by default 1.0E-8</p>
</dd>
<dt><strong>init_type</strong><span class="classifier">str, optional</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'subsampling'</span></code>: for each latent class, extract a subsample whose size is <code class="docutils literal notranslate"><span class="pre">int(np.sqrt(x.shape[0]))</span></code>, 
and use its mean and covariance matrix as an initial values of hn_m_vecs and hn_lambda_mats.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'random_responsibility'</span></code>: randomly assign responsibility to gamma_vecs</p></li>
</ul>
<p>Type of initialization, by default ‘subsampling’</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.LearnModel.estimate_params">
<span class="sig-name descname"><span class="pre">estimate_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'squared'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.LearnModel.estimate_params" title="Link to this definition">#</a></dt>
<dd><p>Estimate the parameter under the given criterion.</p>
<p>Note that the criterion is applied to estimating 
<code class="docutils literal notranslate"><span class="pre">pi_vec</span></code>, <code class="docutils literal notranslate"><span class="pre">a_mat</span></code> <code class="docutils literal notranslate"><span class="pre">mu_vecs</span></code> and <code class="docutils literal notranslate"><span class="pre">lambda_mats</span></code> independently.
Therefore, a tuple of the dirichlet distribution, 
the student’s t-distributions and 
the wishart distributions will be returned when loss=”KL”</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>loss</strong><span class="classifier">str, optional</span></dt><dd><p>Loss function underlying the Bayes risk function, by default “xxx”.
This function supports “squared”, “0-1”, and “KL”.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>Estimates</strong><span class="classifier">a tuple of {numpy ndarray, float, None, or rv_frozen}</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">pi_vec_hat</span></code> : the estimate for pi_vec</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">a_mat_hat</span></code> : the estimate for a_mat</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mu_vecs_hat</span></code> : the estimate for mu_vecs</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Lambda_mats_hat</span></code> : the estimate for Lambda_mats</p></li>
</ul>
<p>The estimated values under the given loss function. 
If it is not exist, <cite>np.nan</cite> will be returned.
If the loss function is “KL”, the posterior distribution itself 
will be returned as rv_frozen object of scipy.stats.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.html#scipy.stats.rv_continuous" title="(in SciPy v1.11.3)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scipy.stats.rv_continuous</span></code></a></dt><dd></dd>
<dt><a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_discrete.html#scipy.stats.rv_discrete" title="(in SciPy v1.11.3)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scipy.stats.rv_discrete</span></code></a></dt><dd></dd>
</dl>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.LearnModel.visualize_posterior">
<span class="sig-name descname"><span class="pre">visualize_posterior</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.LearnModel.visualize_posterior" title="Link to this definition">#</a></dt>
<dd><p>Visualize the posterior distribution for the parameter.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">bayesml</span> <span class="kn">import</span> <span class="n">hiddenmarkovnormal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gen_model</span> <span class="o">=</span> <span class="n">hiddenmarkovnormal</span><span class="o">.</span><span class="n">GenModel</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">c_num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">c_degree</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">mu_vecs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">],[</span><span class="o">-</span><span class="mi">2</span><span class="p">]]),</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">a_mat</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.95</span><span class="p">,</span><span class="mf">0.05</span><span class="p">],[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.9</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span><span class="n">z</span> <span class="o">=</span> <span class="n">gen_model</span><span class="o">.</span><span class="n">gen_sample</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">learn_model</span> <span class="o">=</span> <span class="n">hiddenmarkovnormal</span><span class="o">.</span><span class="n">LearnModel</span><span class="p">(</span><span class="n">c_num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">c_degree</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">learn_model</span><span class="o">.</span><span class="n">update_posterior</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">learn_model</span><span class="o">.</span><span class="n">visualize_posterior</span><span class="p">()</span>
<span class="go">hn_alpha_vec:</span>
<span class="go">[153.65657765  47.34342235]</span>
<span class="go">E[pi_vec]:</span>
<span class="go">[0.76446059 0.23553941]</span>
<span class="go">hn_zeta_vecs:</span>
<span class="go">[[147.64209251   5.51848792]</span>
<span class="go">[  5.51448518  42.3249344 ]]</span>
<span class="go">E[a_mat]</span>
<span class="go">[[0.96396927 0.03603073]</span>
<span class="go">[0.11527074 0.88472926]]</span>
<span class="go">hn_m_vecs (equivalent to E[mu_vecs]):</span>
<span class="go">[[ 1.99456861]</span>
<span class="go">[-2.15581846]]</span>
<span class="go">hn_kappas:</span>
<span class="go">[154.15657765  47.84342235]</span>
<span class="go">hn_nus:</span>
<span class="go">[154.15657765  47.84342235]</span>
<span class="go">hn_w_mats:</span>
<span class="go">[[[0.00525177]]</span>
<span class="go">[[0.02569298]]]</span>
<span class="go">E[lambda_mats]=</span>
<span class="go">[[[0.8095951 ]]</span>
<span class="go">[[1.22924015]]]</span>
</pre></div>
</div>
<img alt="_images/hiddenmarkovnormal_posterior.png" src="_images/hiddenmarkovnormal_posterior.png" />
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.LearnModel.get_p_params">
<span class="sig-name descname"><span class="pre">get_p_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.LearnModel.get_p_params" title="Link to this definition">#</a></dt>
<dd><p>Get the parameters of the predictive distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>p_params</strong><span class="classifier">dict of {str: numpy.ndarray}</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;p_a_mat&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.p_a_mat</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;p_mu_vecs&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.p_mu_vecs</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;p_nus&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.p_nus</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;p_lambda_mats&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.p_lambda_mats</span></code></p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.LearnModel.calc_pred_dist">
<span class="sig-name descname"><span class="pre">calc_pred_dist</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.LearnModel.calc_pred_dist" title="Link to this definition">#</a></dt>
<dd><p>Calculate the parameters of the predictive distribution.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.LearnModel.make_prediction">
<span class="sig-name descname"><span class="pre">make_prediction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'squared'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.LearnModel.make_prediction" title="Link to this definition">#</a></dt>
<dd><p>Predict a new data point under the given criterion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>loss</strong><span class="classifier">str, optional</span></dt><dd><p>Loss function underlying the Bayes risk function, by default “squared”.
This function supports “squared” and “0-1”.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>Predicted_value</strong><span class="classifier">{float, numpy.ndarray}</span></dt><dd><p>The predicted value under the given loss function.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.LearnModel.pred_and_update">
<span class="sig-name descname"><span class="pre">pred_and_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'squared'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_itr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'random_responsibility'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.LearnModel.pred_and_update" title="Link to this definition">#</a></dt>
<dd><p>Predict a new data point and update the posterior sequentially.</p>
<p>h0_params will be overwritten by current hn_params 
before updating hn_params by x.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>x</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>It must be a <cite>c_degree</cite>-dimensional vector</p>
</dd>
<dt><strong>loss</strong><span class="classifier">str, optional</span></dt><dd><p>Loss function underlying the Bayes risk function, by default “squared”.
This function supports “squared” and “0-1”.</p>
</dd>
<dt><strong>max_itr</strong><span class="classifier">int, optional</span></dt><dd><p>maximum number of iterations, by default 100</p>
</dd>
<dt><strong>num_init</strong><span class="classifier">int, optional</span></dt><dd><p>number of initializations, by default 10</p>
</dd>
<dt><strong>tolerance</strong><span class="classifier">float, optional</span></dt><dd><p>convergence croterion of variational lower bound, by default 1.0E-8</p>
</dd>
<dt><strong>init_type</strong><span class="classifier">str, optional</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'random_responsibility'</span></code>: randomly assign responsibility to <code class="docutils literal notranslate"><span class="pre">xi_mats</span></code> and <code class="docutils literal notranslate"><span class="pre">gamma_vecs</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'subsampling'</span></code>: for each latent class, extract a subsample whose size is <code class="docutils literal notranslate"><span class="pre">int(np.sqrt(x.shape[0]))</span></code>. 
and use its mean and covariance matrix as an initial values of hn_m_vecs and hn_lambda_mats.</p></li>
</ul>
<p>Type of initialization, by default ‘random_responsibility’</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>predicted_value</strong><span class="classifier">{float, numpy.ndarray}</span></dt><dd><p>The predicted value under the given loss function.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.LearnModel.estimate_latent_vars">
<span class="sig-name descname"><span class="pre">estimate_latent_vars</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'0-1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">viterbi</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.LearnModel.estimate_latent_vars" title="Link to this definition">#</a></dt>
<dd><p>Estimate latent variables under the given criterion.</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">viterbi</span></code> option is <code class="docutils literal notranslate"><span class="pre">True</span></code>, this function estimates 
the latent variables maximizing the joint distribution. 
If <code class="docutils literal notranslate"><span class="pre">False</span></code>, this function independently estimates the latent 
variables at each time point.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>(sample_length,c_degree)-dimensional ndarray.
All the elements must be real number.</p>
</dd>
<dt><strong>loss</strong><span class="classifier">str, optional</span></dt><dd><p>Loss function underlying the Bayes risk function, by default “0-1”.
If the <code class="docutils literal notranslate"><span class="pre">viterbi</span></code> option is <code class="docutils literal notranslate"><span class="pre">True</span></code>, this function supports only “0-1”. 
Otherwise, “0-1”, “squared”, and “KL” are supported.</p>
</dd>
<dt><strong>viterbi</strong><span class="classifier">bool, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, this function estimates the latent variables as a sequence.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>estimates</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>The estimated values under the given loss function. 
If the <code class="docutils literal notranslate"><span class="pre">viterbi</span></code> option is <code class="docutils literal notranslate"><span class="pre">False</span></code> and loss function is “KL”, 
a marginalized posterior distribution will be returned as 
a numpy.ndarray whose elements consist of occurence 
probabilities for each latent variabl.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.hiddenmarkovnormal.LearnModel.estimate_latent_vars_and_update">
<span class="sig-name descname"><span class="pre">estimate_latent_vars_and_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'0-1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">viterbi</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_itr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'subsampling'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.hiddenmarkovnormal.LearnModel.estimate_latent_vars_and_update" title="Link to this definition">#</a></dt>
<dd><p>Estimate latent variables and update the posterior sequentially.</p>
<p>h0_params will be overwritten by current hn_params 
before updating hn_params by x</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>x</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>It must be a <cite>c_degree</cite>-dimensional vector</p>
</dd>
<dt><strong>loss</strong><span class="classifier">str, optional</span></dt><dd><p>Loss function underlying the Bayes risk function, by default “0-1”.
If the <code class="docutils literal notranslate"><span class="pre">viterbi</span></code> option is <code class="docutils literal notranslate"><span class="pre">True</span></code>, this function supports only “0-1”. 
Otherwise, “0-1”, “squared”, and “KL” are supported.</p>
</dd>
<dt><strong>viterbi</strong><span class="classifier">bool, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, this function estimates the latent variables as a sequence.</p>
</dd>
<dt><strong>max_itr</strong><span class="classifier">int, optional</span></dt><dd><p>maximum number of iterations, by default 100</p>
</dd>
<dt><strong>num_init</strong><span class="classifier">int, optional</span></dt><dd><p>number of initializations, by default 10</p>
</dd>
<dt><strong>tolerance</strong><span class="classifier">float, optional</span></dt><dd><p>convergence croterion of variational lower bound, by default 1.0E-8</p>
</dd>
<dt><strong>init_type</strong><span class="classifier">str, optional</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'random_responsibility'</span></code>: randomly assign responsibility to <code class="docutils literal notranslate"><span class="pre">xi_mats</span></code> and <code class="docutils literal notranslate"><span class="pre">gamma_vecs</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'subsampling'</span></code>: for each latent class, extract a subsample whose size is <code class="docutils literal notranslate"><span class="pre">int(np.sqrt(x.shape[0]))</span></code>.
and use its mean and covariance matrix as an initial values of hn_m_vecs and hn_lambda_mats.</p></li>
</ul>
<p>Type of initialization, by default <code class="docutils literal notranslate"><span class="pre">'random_responsibility'</span></code></p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>estimates</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>The estimated values under the given loss function. 
If the <code class="docutils literal notranslate"><span class="pre">viterbi</span></code> option is <code class="docutils literal notranslate"><span class="pre">False</span></code> and loss function is “KL”, 
a marginalized posterior distribution will be returned as 
a numpy.ndarray whose elements consist of occurence 
probabilities for each latent variabl.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="bayesml.gaussianmixture.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">bayesml.gaussianmixture package</p>
      </div>
    </a>
    <a class="right-next"
       href="bayesml.linearregression.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">bayesml.linearregression package</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-bayesml.hiddenmarkovnormal">Module contents</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel"><code class="docutils literal notranslate"><span class="pre">GenModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.get_constants"><code class="docutils literal notranslate"><span class="pre">GenModel.get_constants()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.set_params"><code class="docutils literal notranslate"><span class="pre">GenModel.set_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.set_h_params"><code class="docutils literal notranslate"><span class="pre">GenModel.set_h_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.get_params"><code class="docutils literal notranslate"><span class="pre">GenModel.get_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.get_h_params"><code class="docutils literal notranslate"><span class="pre">GenModel.get_h_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.gen_params"><code class="docutils literal notranslate"><span class="pre">GenModel.gen_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.gen_sample"><code class="docutils literal notranslate"><span class="pre">GenModel.gen_sample()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.save_sample"><code class="docutils literal notranslate"><span class="pre">GenModel.save_sample()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.GenModel.visualize_model"><code class="docutils literal notranslate"><span class="pre">GenModel.visualize_model()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel"><code class="docutils literal notranslate"><span class="pre">LearnModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.get_constants"><code class="docutils literal notranslate"><span class="pre">LearnModel.get_constants()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.set_h0_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.set_h0_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.get_h0_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.get_h0_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.set_hn_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.set_hn_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.get_hn_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.get_hn_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.update_posterior"><code class="docutils literal notranslate"><span class="pre">LearnModel.update_posterior()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.estimate_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.estimate_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.visualize_posterior"><code class="docutils literal notranslate"><span class="pre">LearnModel.visualize_posterior()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.get_p_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.get_p_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.calc_pred_dist"><code class="docutils literal notranslate"><span class="pre">LearnModel.calc_pred_dist()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.make_prediction"><code class="docutils literal notranslate"><span class="pre">LearnModel.make_prediction()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.pred_and_update"><code class="docutils literal notranslate"><span class="pre">LearnModel.pred_and_update()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.estimate_latent_vars"><code class="docutils literal notranslate"><span class="pre">LearnModel.estimate_latent_vars()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.hiddenmarkovnormal.LearnModel.estimate_latent_vars_and_update"><code class="docutils literal notranslate"><span class="pre">LearnModel.estimate_latent_vars_and_update()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By BayesML Developers
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022, BayesML Developers.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>